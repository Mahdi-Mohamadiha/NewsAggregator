{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346b0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser as fp\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e10cc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bozo': True, 'entries': [], 'feed': {}, 'headers': {}, 'bozo_exception': <HTTPError 307: 'The HTTP server returned a redirect error that would lead to an infinite loop.\\nThe last 30x error message was:\\nTemporary Redirect'>}\n"
     ]
    }
   ],
   "source": [
    "feed = fp.parse('https://www.isna.ir/rss')\n",
    "print(feed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8b38ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "urls = ['https://www.irna.ir/rss','https://www.isna.ir/rss','https://fararu.com/fa/rss/allnews']\n",
    "\n",
    "def get_num_titles(feed):\n",
    "    return len(feed.entries)\n",
    "\n",
    "\n",
    "def get_all_titles(feed):\n",
    "    for f in feed.entries:\n",
    "        print(f.title)\n",
    "\n",
    "        \n",
    "def count_news(urls):\n",
    "    total_news_cnt = 0\n",
    "    for url in urls:\n",
    "        feed = fp.parse(url)\n",
    "        total_news_cnt = total_news_cnt + get_num_titles(feed) \n",
    "    return total_news_cnt\n",
    "\n",
    "\n",
    "def paginate(total_news_cnt,news_per_page):\n",
    "    total_page = total_news_cnt // news_per_page\n",
    "    return (total_page,news_per_page)\n",
    "\n",
    "\n",
    "\n",
    "paging = paginate(count_news(urls),20)\n",
    "\n",
    "news = {\n",
    "    \"total_pages\": paging[0],\n",
    "    \"page\":0,\n",
    "    \"news\":[]\n",
    "    }\n",
    "\n",
    "# def get_news(feed,news,p):\n",
    "#     i = 0\n",
    "#     for f in feed.entries:\n",
    "#         if(f.enclosures):\n",
    "#             enclink = f.enclosures[0]['href']\n",
    "#             enctype = f.enclosures[0]['type']\n",
    "#         else:\n",
    "#             enclink = None\n",
    "#             enctype = None\n",
    "#         news['page'] = 0\n",
    "#         news['news'].append({\n",
    "#             \"id\" : i,\n",
    "#             \"title\" : f.title,\n",
    "#             \"pubdate\" : f.published,\n",
    "#             \"enclosure\" : {\n",
    "#                 \"link\" : enclink,\n",
    "#                 \"type\" : enctype\n",
    "#             }\n",
    "#         })\n",
    "            \n",
    "#         i = i + 1\n",
    "#     return news\n",
    "        \n",
    "\n",
    "def get_news(urls):\n",
    "    paging = paginate(count_news(urls),20) # paging(totalnumbesofpage,newsperpage)\n",
    "    news = {\n",
    "    \"total_pages\": paging[0],\n",
    "    \"page\":0,\n",
    "    \"news\":[]\n",
    "    }\n",
    "    i = 0\n",
    "    current_page = 0\n",
    "    \n",
    "    for url in urls:\n",
    "        feed = fp.parse(url)\n",
    "        for f in feed.entries:\n",
    "            if(i == 19):\n",
    "                current_page = current_page + 1\n",
    "                i = 0\n",
    "            if(f.enclosures):\n",
    "                enclink = f.enclosures[0]['href']\n",
    "                enctype = f.enclosures[0]['type']\n",
    "            else:\n",
    "                enclink = None\n",
    "                enctype = None\n",
    "            news['page'] = current_page\n",
    "            news['news'].append({\n",
    "                \"id\" : i,\n",
    "                \"title\" : f.title,\n",
    "                \"pubdate\" : f.published,\n",
    "                \"enclosure\" : {\n",
    "                    \"link\" : enclink,\n",
    "                    \"type\" : enctype\n",
    "                }\n",
    "                })\n",
    "            i = i + 1\n",
    "    return news\n",
    "\n",
    "n = get_news(urls)\n",
    "# for url in urls:\n",
    "#     feed = fp.parse(url)\n",
    "#     n = get_news(feed,news)\n",
    "    \n",
    "\n",
    "    \n",
    "with open(\"presentation.json\",\"w\", encoding='utf-8') as jsonfile:\n",
    "    json.dump(n,jsonfile,ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c1728c19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import feedparser as fp\n",
    "import json\n",
    "import re\n",
    "\n",
    "_my_date_pattern = re.compile(\n",
    "    r'(\\d{,2})/(\\d{,2})/(\\d{4}) (\\d{,2}):(\\d{2}):(\\d{2})')\n",
    "\n",
    "def myDateHandler(aDateString):\n",
    "    \"\"\"parse a UTC date in MM/DD/YYYY HH:MM:SS format\"\"\"\n",
    "    month, day, year, hour, minute, second = \\\n",
    "        _my_date_pattern.search(aDateString).groups()\n",
    "    return (int(year), int(month), int(day), \\\n",
    "        int(hour), int(minute), int(second), 0, 0, 0)\n",
    "\n",
    "fp.registerDateHandler(myDateHandler)\n",
    "\n",
    "\n",
    "urls =[\"https://www.irna.ir/rss\",'https://fararu.com/fa/rss/allnews']\n",
    "\n",
    "def get_news(urls):\n",
    "    news =[]\n",
    "    for url in urls:\n",
    "        feed = fp.parse(url)\n",
    "        for f in feed.entries:\n",
    "#             print(f.tags[0]['scheme'])\n",
    "            if(f.enclosures):\n",
    "                enclink = f.enclosures[0]['href']\n",
    "                enctype = f.enclosures[0]['type']\n",
    "            else:\n",
    "                enclink = None\n",
    "                enctype = None\n",
    "            if ('tags' in f ):\n",
    "                category = f.tags[0]['scheme']\n",
    "            else: \n",
    "                category = None\n",
    "                \n",
    "            if ('description' in f):\n",
    "                description = f.description\n",
    "            else:\n",
    "                description = None\n",
    "            news.append({\n",
    "                \"title\" : f.title,\n",
    "                \"description\" : description,\n",
    "#                 print(\"g\")\n",
    "                \"pubdate\": {\n",
    "                                \"date\" : f.published,\n",
    "                                \"year\" : f.published_parsed.tm_year,\n",
    "                                \"month\" : f.published_parsed.tm_mon,\n",
    "                                \"day\" : f.published_parsed.tm_mday,\n",
    "                                \"hour\" : f.published_parsed.tm_hour,\n",
    "                                \"minute\" : f.published_parsed.tm_min},\n",
    "                \"category\" : category,\n",
    "                \"enclosure\" : {\n",
    "                    \"link\" : enclink,\n",
    "                    \"type\" : enctype\n",
    "                }\n",
    "                })\n",
    "    return news\n",
    "latest_news = get_news(urls)\n",
    "with open(\"latest_news.json\",\"w\", encoding='utf-8') as jsonfile:\n",
    "    json.dump(latest_news,jsonfile,ensure_ascii=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "adb39a8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=7, tm_min=55, tm_sec=52, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 07:55:52 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=7, tm_min=49, tm_sec=55, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 07:49:55 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=7, tm_min=42, tm_sec=31, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 07:42:31 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=7, tm_min=8, tm_sec=59, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 07:08:59 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=7, tm_min=0, tm_sec=55, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 07:00:55 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=51, tm_sec=54, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:51:54 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=46, tm_sec=32, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:46:32 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=43, tm_sec=22, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:43:22 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=41, tm_sec=5, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:41:05 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=37, tm_sec=2, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:37:02 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=34, tm_sec=41, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:34:41 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=7, tm_sec=45, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:07:45 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=0, tm_sec=0, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:00:00 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=5, tm_min=28, tm_sec=17, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 05:28:17 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=4, tm_min=50, tm_sec=4, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 04:50:04 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=4, tm_min=45, tm_sec=50, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 04:45:50 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=19, tm_min=15, tm_sec=26, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 19:15:26 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=18, tm_min=35, tm_sec=11, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 18:35:11 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=17, tm_min=0, tm_sec=57, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 17:00:57 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=14, tm_min=52, tm_sec=52, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 14:52:52 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=14, tm_min=39, tm_sec=45, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 14:39:45 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=14, tm_min=34, tm_sec=6, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 14:34:06 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=14, tm_min=28, tm_sec=23, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 14:28:23 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=14, tm_min=22, tm_sec=59, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 14:22:59 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=14, tm_min=11, tm_sec=48, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 14:11:48 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=13, tm_min=55, tm_sec=39, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 13:55:39 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=13, tm_min=48, tm_sec=33, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 13:48:33 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=13, tm_min=1, tm_sec=22, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 13:01:22 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=12, tm_min=30, tm_sec=0, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 12:30:00 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=11, tm_min=21, tm_sec=16, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 11:21:16 +0000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "_my_date_pattern = re.compile(\n",
    "    r'(\\d{,2})/(\\d{,2})/(\\d{4}) (\\d{,2}):(\\d{2}):(\\d{2})')\n",
    "\n",
    "def myDateHandler(aDateString):\n",
    "    \"\"\"parse a UTC date in MM/DD/YYYY HH:MM:SS format\"\"\"\n",
    "    month, day, year, hour, minute, second = \\\n",
    "        _my_date_pattern.search(aDateString).groups()\n",
    "    return (int(year), int(month), int(day), \\\n",
    "        int(hour), int(minute), int(second), 0, 0, 0)\n",
    "urls=[\"https://www.irna.ir/rss\",'https://fararu.com/fa/rss/allnews','https://www.isna.ir/rss','https://www.etemadonline.com/fa/feeds/?p=Y2F0ZWdvcmllcz0yMw%2C%2C']\n",
    "fp.registerDateHandler(myDateHandler)\n",
    "feed = fp.parse(urls[3])\n",
    "# print(feed.entries)\n",
    "#print(feed)\n",
    "for f in feed.entries:\n",
    "    print(f.published_parsed)\n",
    "    print(f.published)\n",
    "#     print(f.published)\n",
    "#     print(f.category)\n",
    "    \n",
    "    \n",
    "\n",
    "# print(feed.entries[0].enclosures[0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556447b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sysproj",
   "language": "python",
   "name": "sysproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
