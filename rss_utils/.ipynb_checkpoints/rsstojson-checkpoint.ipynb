{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346b0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser as fp\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e10cc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'جزای ۲ میلیارد ریالی قاچاقچی تلفن همراه', 'title_detail': {'type': 'text/plain', 'language': 'fa', 'base': 'https://www.irna.ir/rss', 'value': 'جزای ۲ میلیارد ریالی قاچاقچی تلفن همراه'}, 'links': [{'rel': 'alternate', 'type': 'text/html', 'href': 'https://www.irna.ir/news/85029288/جزای-۲-میلیارد-ریالی-قاچاقچی-تلفن-همراه'}, {'type': 'image/jpeg', 'href': 'https://img9.irna.ir/d/r1/2019/07/08/4/156457967.jpg', 'rel': 'enclosure'}], 'link': 'https://www.irna.ir/news/85029288/جزای-۲-میلیارد-ریالی-قاچاقچی-تلفن-همراه', 'summary': 'تهران - ایرنا - مدیرکل تعزیرات حکومتی شهرستان\\u200cهای تهران از محکومیت ۲ میلیارد ریالی قاچاقچی تلفن همراه خبر داد.', 'summary_detail': {'type': 'text/html', 'language': 'fa', 'base': 'https://www.irna.ir/rss', 'value': 'تهران - ایرنا - مدیرکل تعزیرات حکومتی شهرستان\\u200cهای تهران از محکومیت ۲ میلیارد ریالی قاچاقچی تلفن همراه خبر داد.'}, 'content': [{'type': 'text/html', 'language': 'fa', 'base': 'https://www.irna.ir/rss', 'value': ''}], 'tags': [{'term': 'جامعه > حقوقی و  قضایی', 'scheme': 'حقوقي - قضايي', 'label': None}], 'published': 'Mon, 13 Feb 2023 13:44:33 GMT', 'published_parsed': time.struct_time(tm_year=2023, tm_mon=2, tm_mday=13, tm_hour=13, tm_min=44, tm_sec=33, tm_wday=0, tm_yday=44, tm_isdst=0), 'authors': [{'name': 'حنانه شفیعی'}], 'author': 'حنانه شفیعی', 'author_detail': {'name': 'حنانه شفیعی'}, 'id': 'https://www.irna.ir/news/85029288/جزای-۲-میلیارد-ریالی-قاچاقچی-تلفن-همراه', 'guidislink': False}\n",
      "https://www.irna.ir/news/85029288/جزای-۲-میلیارد-ریالی-قاچاقچی-تلفن-همراه\n",
      "جزای ۲ میلیارد ریالی قاچاقچی تلفن همراه\n",
      "تهران - ایرنا - مدیرکل تعزیرات حکومتی شهرستان‌های تهران از محکومیت ۲ میلیارد ریالی قاچاقچی تلفن همراه خبر داد.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\feedparser\\util.py:113\u001b[0m, in \u001b[0;36mFeedParserDict.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, realkey):\n\u001b[0;32m    112\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, realkey)\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'type'"
     ]
    }
   ],
   "source": [
    "feed = fp.parse('https://www.irna.ir/rss')\n",
    "for f in feed.entries:\n",
    "    print(f)\n",
    "    print(f['link'])\n",
    "    print(f['title'])\n",
    "    print(f['description'])\n",
    "    print(f['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8b38ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "urls = ['https://www.irna.ir/rss','https://www.isna.ir/rss','https://fararu.com/fa/rss/allnews']\n",
    "\n",
    "def get_num_titles(feed):\n",
    "    return len(feed.entries)\n",
    "\n",
    "\n",
    "def get_all_titles(feed):\n",
    "    for f in feed.entries:\n",
    "        print(f.title)\n",
    "\n",
    "        \n",
    "def count_news(urls):\n",
    "    total_news_cnt = 0\n",
    "    for url in urls:\n",
    "        feed = fp.parse(url)\n",
    "        total_news_cnt = total_news_cnt + get_num_titles(feed) \n",
    "    return total_news_cnt\n",
    "\n",
    "\n",
    "def paginate(total_news_cnt,news_per_page):\n",
    "    total_page = total_news_cnt // news_per_page\n",
    "    return (total_page,news_per_page)\n",
    "\n",
    "\n",
    "\n",
    "paging = paginate(count_news(urls),20)\n",
    "\n",
    "news = {\n",
    "    \"total_pages\": paging[0],\n",
    "    \"page\":0,\n",
    "    \"news\":[]\n",
    "    }\n",
    "\n",
    "# def get_news(feed,news,p):\n",
    "#     i = 0\n",
    "#     for f in feed.entries:\n",
    "#         if(f.enclosures):\n",
    "#             enclink = f.enclosures[0]['href']\n",
    "#             enctype = f.enclosures[0]['type']\n",
    "#         else:\n",
    "#             enclink = None\n",
    "#             enctype = None\n",
    "#         news['page'] = 0\n",
    "#         news['news'].append({\n",
    "#             \"id\" : i,\n",
    "#             \"title\" : f.title,\n",
    "#             \"pubdate\" : f.published,\n",
    "#             \"enclosure\" : {\n",
    "#                 \"link\" : enclink,\n",
    "#                 \"type\" : enctype\n",
    "#             }\n",
    "#         })\n",
    "            \n",
    "#         i = i + 1\n",
    "#     return news\n",
    "        \n",
    "\n",
    "def get_news(urls):\n",
    "    paging = paginate(count_news(urls),20) # paging(totalnumbesofpage,newsperpage)\n",
    "    news = {\n",
    "    \"total_pages\": paging[0],\n",
    "    \"page\":0,\n",
    "    \"news\":[]\n",
    "    }\n",
    "    i = 0\n",
    "    current_page = 0\n",
    "    \n",
    "    for url in urls:\n",
    "        feed = fp.parse(url)\n",
    "        for f in feed.entries:\n",
    "            if(i == 19):\n",
    "                current_page = current_page + 1\n",
    "                i = 0\n",
    "            if(f.enclosures):\n",
    "                enclink = f.enclosures[0]['href']\n",
    "                enctype = f.enclosures[0]['type']\n",
    "            else:\n",
    "                enclink = None\n",
    "                enctype = None\n",
    "            news['page'] = current_page\n",
    "            news['news'].append({\n",
    "                \"id\" : i,\n",
    "                \"title\" : f.title,\n",
    "                \"pubdate\" : f.published,\n",
    "                \"enclosure\" : {\n",
    "                    \"link\" : enclink,\n",
    "                    \"type\" : enctype\n",
    "                }\n",
    "                })\n",
    "            i = i + 1\n",
    "    return news\n",
    "\n",
    "n = get_news(urls)\n",
    "# for url in urls:\n",
    "#     feed = fp.parse(url)\n",
    "#     n = get_news(feed,news)\n",
    "    \n",
    "\n",
    "    \n",
    "with open(\"presentation.json\",\"w\", encoding='utf-8') as jsonfile:\n",
    "    json.dump(n,jsonfile,ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c1728c19",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import feedparser as fp\n",
    "import json\n",
    "import re\n",
    "\n",
    "_my_date_pattern = re.compile(\n",
    "    r'(\\d{,2})/(\\d{,2})/(\\d{4}) (\\d{,2}):(\\d{2}):(\\d{2})')\n",
    "\n",
    "def myDateHandler(aDateString):\n",
    "    \"\"\"parse a UTC date in MM/DD/YYYY HH:MM:SS format\"\"\"\n",
    "    month, day, year, hour, minute, second = \\\n",
    "        _my_date_pattern.search(aDateString).groups()\n",
    "    return (int(year), int(month), int(day), \\\n",
    "        int(hour), int(minute), int(second), 0, 0, 0)\n",
    "\n",
    "fp.registerDateHandler(myDateHandler)\n",
    "\n",
    "\n",
    "urls =[\"https://www.irna.ir/rss\",'https://fararu.com/fa/rss/allnews']\n",
    "\n",
    "def get_news(urls):\n",
    "    news =[]\n",
    "    for url in urls:\n",
    "        feed = fp.parse(url)\n",
    "        for f in feed.entries:\n",
    "#             print(f.tags[0]['scheme'])\n",
    "            if(f.enclosures):\n",
    "                enclink = f.enclosures[0]['href']\n",
    "                enctype = f.enclosures[0]['type']\n",
    "            else:\n",
    "                enclink = None\n",
    "                enctype = None\n",
    "            if ('tags' in f ):\n",
    "                category = f.tags[0]['scheme']\n",
    "            else: \n",
    "                category = None\n",
    "                \n",
    "            if ('description' in f):\n",
    "                description = f.description\n",
    "            else:\n",
    "                description = None\n",
    "            news.append({\n",
    "                \"title\" : f.title,\n",
    "                \"description\" : description,\n",
    "#                 print(\"g\")\n",
    "                \"pubdate\": {\n",
    "                                \"date\" : f.published,\n",
    "                                \"year\" : f.published_parsed.tm_year,\n",
    "                                \"month\" : f.published_parsed.tm_mon,\n",
    "                                \"day\" : f.published_parsed.tm_mday,\n",
    "                                \"hour\" : f.published_parsed.tm_hour,\n",
    "                                \"minute\" : f.published_parsed.tm_min},\n",
    "                \"category\" : category,\n",
    "                \"enclosure\" : {\n",
    "                    \"link\" : enclink,\n",
    "                    \"type\" : enctype\n",
    "                }\n",
    "                })\n",
    "    return news\n",
    "latest_news = get_news(urls)\n",
    "with open(\"latest_news.json\",\"w\", encoding='utf-8') as jsonfile:\n",
    "    json.dump(latest_news,jsonfile,ensure_ascii=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "adb39a8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=7, tm_min=55, tm_sec=52, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 07:55:52 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=7, tm_min=49, tm_sec=55, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 07:49:55 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=7, tm_min=42, tm_sec=31, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 07:42:31 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=7, tm_min=8, tm_sec=59, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 07:08:59 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=7, tm_min=0, tm_sec=55, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 07:00:55 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=51, tm_sec=54, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:51:54 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=46, tm_sec=32, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:46:32 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=43, tm_sec=22, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:43:22 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=41, tm_sec=5, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:41:05 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=37, tm_sec=2, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:37:02 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=34, tm_sec=41, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:34:41 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=7, tm_sec=45, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:07:45 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=6, tm_min=0, tm_sec=0, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 06:00:00 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=5, tm_min=28, tm_sec=17, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 05:28:17 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=4, tm_min=50, tm_sec=4, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 04:50:04 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=2, tm_hour=4, tm_min=45, tm_sec=50, tm_wday=3, tm_yday=33, tm_isdst=0)\n",
      "Thu, 02 Feb 2023 04:45:50 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=19, tm_min=15, tm_sec=26, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 19:15:26 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=18, tm_min=35, tm_sec=11, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 18:35:11 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=17, tm_min=0, tm_sec=57, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 17:00:57 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=14, tm_min=52, tm_sec=52, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 14:52:52 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=14, tm_min=39, tm_sec=45, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 14:39:45 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=14, tm_min=34, tm_sec=6, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 14:34:06 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=14, tm_min=28, tm_sec=23, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 14:28:23 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=14, tm_min=22, tm_sec=59, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 14:22:59 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=14, tm_min=11, tm_sec=48, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 14:11:48 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=13, tm_min=55, tm_sec=39, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 13:55:39 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=13, tm_min=48, tm_sec=33, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 13:48:33 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=13, tm_min=1, tm_sec=22, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 13:01:22 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=12, tm_min=30, tm_sec=0, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 12:30:00 +0000\n",
      "time.struct_time(tm_year=2023, tm_mon=2, tm_mday=1, tm_hour=11, tm_min=21, tm_sec=16, tm_wday=2, tm_yday=32, tm_isdst=0)\n",
      "Wed, 01 Feb 2023 11:21:16 +0000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "_my_date_pattern = re.compile(\n",
    "    r'(\\d{,2})/(\\d{,2})/(\\d{4}) (\\d{,2}):(\\d{2}):(\\d{2})')\n",
    "\n",
    "def myDateHandler(aDateString):\n",
    "    \"\"\"parse a UTC date in MM/DD/YYYY HH:MM:SS format\"\"\"\n",
    "    month, day, year, hour, minute, second = \\\n",
    "        _my_date_pattern.search(aDateString).groups()\n",
    "    return (int(year), int(month), int(day), \\\n",
    "        int(hour), int(minute), int(second), 0, 0, 0)\n",
    "urls=[\"https://www.irna.ir/rss\",'https://fararu.com/fa/rss/allnews','https://www.isna.ir/rss','https://www.etemadonline.com/fa/feeds/?p=Y2F0ZWdvcmllcz0yMw%2C%2C']\n",
    "fp.registerDateHandler(myDateHandler)\n",
    "feed = fp.parse(urls[3])\n",
    "# print(feed.entries)\n",
    "#print(feed)\n",
    "for f in feed.entries:\n",
    "    print(f.published_parsed)\n",
    "    print(f.published)\n",
    "#     print(f.published)\n",
    "#     print(f.category)\n",
    "    \n",
    "    \n",
    "\n",
    "# print(feed.entries[0].enclosures[0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556447b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The following arguments have not been supplied: urls",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28mprint\u001b[39m(f\u001b[38;5;241m.\u001b[39mtitle)\n\u001b[0;32m     11\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m BlockingScheduler()\n\u001b[1;32m---> 12\u001b[0m \u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_job\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minterval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mminutes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# print(feed)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\apscheduler\\schedulers\\base.py:438\u001b[0m, in \u001b[0;36mBaseScheduler.add_job\u001b[1;34m(self, func, trigger, args, kwargs, id, name, misfire_grace_time, coalesce, max_instances, next_run_time, jobstore, executor, replace_existing, **trigger_args)\u001b[0m\n\u001b[0;32m    423\u001b[0m job_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    424\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrigger\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_trigger(trigger, trigger_args),\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexecutor\u001b[39m\u001b[38;5;124m'\u001b[39m: executor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext_run_time\u001b[39m\u001b[38;5;124m'\u001b[39m: next_run_time\n\u001b[0;32m    435\u001b[0m }\n\u001b[0;32m    436\u001b[0m job_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m((key, value) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m six\u001b[38;5;241m.\u001b[39miteritems(job_kwargs) \u001b[38;5;28;01mif\u001b[39;00m\n\u001b[0;32m    437\u001b[0m                   value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m undefined)\n\u001b[1;32m--> 438\u001b[0m job \u001b[38;5;241m=\u001b[39m Job(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mjob_kwargs)\n\u001b[0;32m    440\u001b[0m \u001b[38;5;66;03m# Don't really add jobs to job stores before the scheduler is up and running\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobstores_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\apscheduler\\job.py:49\u001b[0m, in \u001b[0;36mJob.__init__\u001b[1;34m(self, scheduler, id, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_scheduler \u001b[38;5;241m=\u001b[39m scheduler\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobstore_alias \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modify(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m uuid4()\u001b[38;5;241m.\u001b[39mhex, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\apscheduler\\job.py:180\u001b[0m, in \u001b[0;36mJob._modify\u001b[1;34m(self, **changes)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kwargs, six\u001b[38;5;241m.\u001b[39mstring_types) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kwargs, Mapping):\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkwargs must be a dict-like object\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 180\u001b[0m \u001b[43mcheck_callable_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m approved[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m func\n\u001b[0;32m    183\u001b[0m approved[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunc_ref\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m func_ref\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\apscheduler\\util.py:391\u001b[0m, in \u001b[0;36mcheck_callable_args\u001b[1;34m(func, args, kwargs)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# Check that the number of positional arguments minus the number of matched kwargs matches the\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;66;03m# argspec\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsatisfied_args:\n\u001b[1;32m--> 391\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe following arguments have not been supplied: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    392\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(unsatisfied_args))\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# Check that all keyword-only arguments have been supplied\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsatisfied_kwargs:\n",
      "\u001b[1;31mValueError\u001b[0m: The following arguments have not been supplied: urls"
     ]
    }
   ],
   "source": [
    "import feedparser as fp\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "urls = [\"https://www.irna.ir/rss\"] \n",
    "    \n",
    "    \n",
    "def fetch(urls):\n",
    "    feed = fp.parse(urls[0])\n",
    "    for f in feed.entries:\n",
    "        print(f.title)\n",
    "    \n",
    "scheduler = BlockingScheduler()\n",
    "scheduler.add_job(fetch,'interval',minutes = 1)\n",
    "scheduler.start()\n",
    "\n",
    "     \n",
    "\n",
    "    \n",
    "# print(feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5015a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sysproj",
   "language": "python",
   "name": "sysproj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
